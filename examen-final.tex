% File RobotsMonstruicidas.tex
\documentclass[10pt,twocolumn]{article}
\usepackage[margin=2cm]{geometry}
\usepackage{times} % Times Roman font
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath, amsthm, amsfonts}
\usepackage{algorithm, algorithmic}  
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{cite}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, fit, backgrounds}

% Configuración para código Python
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)}
}

\title{Procedimiento Metodológico para la Generación de un Dataset Etiquetado orientado a la Clasificación de Locutores Políticos mediante Análisis de Audio}

\author{
  Orlando José Kuan Becerra$^1$, Alex Celestino León Pacheco$^1$, Edwin Jhon Minchán Ramos$^1$, \\
  Víctor Fernando Montes Jaramillo$^1$, Marco Antonio Nina Aguilar$^1$ \\
  \\
  $^1$Universidad Nacional de Ingeniería, Facultad de Ingeniería Industrial y de Sistemas \\
  Av. Túpac Amaru 210, Rímac, Lima, Perú \\
  {\tt \{orlando.kuan.b, alex.leon.p, edwin.minchan.r, victor.montes.j, marco.nina.a\}@uni.edu.pe}
}

\date{28 de enero de 2026
}

\begin{document}
\maketitle

\noindent {\bf Curso:} MIA-103 Machine Learning \\
{\bf Docente:} Mg. Samuel Oporto Díaz \\
{\bf Sección:} B \\
{\bf Ciclo Académico:} 2025-2

\begin{abstract}
    El presente trabajo de investigación desarrolla un sistema de información basado en agentes inteligentes para abordar la problemática de la iluminación mixta en entornos de oficina doméstica (\textit{Home Office}). El problema se define formalmente como una situación de diagnóstico, caracterizada por un conjunto de variables espectrales que describen la interacción estocástica entre la luz natural, la iluminación LED y la emisión de luz azul de los monitores.

    La metodología empleada sigue un diseño experimental con estrategia \textit{Ex-Ante}, donde se identificaron previamente las categorías a diagnosticar (Luz Natural, LED, Pantalla) y se prepararon los escenarios físicos controlados antes de proceder al muestreo. La arquitectura del sistema integra componentes de Hardware (Webcam como sensor matricial) y Software (Python/OpenCV), ejecutando un proceso de Adquisición de Datos (DAQ) que asegura la calidad de las señales captadas para la conformación del dataset.

    En la fase de ingeniería de datos, se realizó una descripción estadística exhaustiva para identificar la calidad predictiva de los atributos extraídos (espacios de color HSV y CIELAB). Se generó un ranking de atributos basado en el cálculo de la ganancia de información, permitiendo seleccionar las variables con mayor impacto en la discriminación de clases (Alta, Media, Baja). Posteriormente, se aplicaron técnicas de preparación de datos, incluyendo la normalización y el balanceo de clases, para optimizar el entrenamiento.

    Para la etapa de modelado, se cumplió con el requisito de implementar cuatro algoritmos de clasificación distintos: \textit{K-Nearest Neighbors} (KNN), \textit{Support Vector Machine} (SVM), \textit{Random Forest} y XGBoost. Se identificaron los parámetros óptimos y se analizaron los coeficientes de ajuste de cada modelo. Finalmente, el proyecto concluye con la optimización de parámetros orientada a maximizar los indicadores de rendimiento clave, específicamente el Valor Predictivo Positivo (VPP), garantizando un diagnóstico robusto y preciso de la fuente de luz dominante.
    
    \vspace{0.5cm}
    \textbf{Palabras clave:} Clasificación de Fuentes de Luz, Aprendizaje Automático, Sensores de Imagen, Espacios de Color, Entornos Inteligentes.
\end{abstract}

{\bf Palabras clave:} Reconocimiento de Locutores, Dataset de Audio, Pipeline ETL, Ingeniería de Características, Procesamiento Digital de Señales, PCA.

\section{Introducción}

\subsection{Realidad Problemática}

La transición global hacia entornos de trabajo híbridos (\textit{Home Office}) ha transformado las dinámicas de iluminación en los espacios residenciales. A diferencia de las oficinas corporativas con iluminación controlada y estandarizada, los entornos domésticos presentan una interacción estocástica de fuentes de luz: la radiación solar variable, la iluminación artificial LED de diversas temperaturas y la emisión de luz azul directa de monitores y pantallas.

Esta variabilidad no controlada genera dos problemas críticos:

\begin{description}
    \item[Salud Visual:] La fatiga ocular y la alteración del ritmo circadiano debido a la exposición prolongada a mezclas inadecuadas de temperatura de color.
    \item[Visión Computacional:] Los algoritmos de balance de blancos automático (AWB) en cámaras web fallan al no poder distinguir si una escena es "azul" porque es de noche o porque el usuario está frente a un monitor, afectando la calidad de imagen en videoconferencias y sistemas de seguridad.
\end{description}

Por lo tanto, se requiere un sistema de diagnóstico capaz de identificar la fuente de luz dominante en tiempo real utilizando \textit{hardware} accesible.

\subsection{Revisión Bibliográfica}

La caracterización de fuentes lumínicas ha evolucionado desde la radiometría tradicional hacia el uso de sensores ópticos integrados con Inteligencia Artificial. La literatura reciente valida el uso de características estadísticas y modelos de ensamble para este propósito.

Rhudy et al. \cite{rhudy} desarrollaron un sistema de clasificación de entornos (interior/exterior) utilizando sensores de temperatura de color y luminosidad. Su estudio comparativo concluyó que los Árboles Embolsados (\textit{Bagged Trees}) superaron en rendimiento (99.2\%) a las Redes Neuronales Artificiales (ANN) y a las Máquinas de Soporte Vectorial (SVM). Este hallazgo fundamenta la elección de \textit{Random Forest} en la presente investigación, demostrando que para datos tabulares de sensores, los métodos de ensamble ofrecen mayor robustez que los modelos profundos.

En cuanto a la extracción de características, Mestiraihi et al. \cite{mestiraihi} propusieron el uso de \textit{Visible Light Sensing} (VLS) para estimar ocupación, demostrando que la función de densidad de probabilidad (PDF) de la potencia óptica recibida contiene patrones únicos. Este enfoque valida nuestra metodología de utilizar la asimetría del histograma (\textit{skew\_v}) como descriptor morfológico de la luz, más allá de los valores medios de intensidad.

Por otro lado, la aplicación de algoritmos de \textit{gradient boosting} en señales visuales fue abordada por Lao et al. \cite{lao} en la clasificación de fuentes de luz urbana nocturna. Los autores combinaron parámetros fotográficos (ISO, obturación) con el algoritmo XGBoost, logrando diferenciar tecnologías de iluminación (LED, Sodio) con alta precisión. Esto justifica la inclusión de XGBoost como modelo de referencia (\textit{benchmark}) en nuestro estudio. Finalmente, Ishii \cite{ishii} refuerza la tendencia de sustituir compensadores rígidos por enfoques de aprendizaje automático para adaptarse a condiciones dinámicas de iluminación.

La investigación se ubica en el contexto de la Visión por Computador y el procesamiento de imágenes, específicamente en la oficina doméstica (\textit{Home Office}) de un programador. En este entorno ocurre una interacción dinámica y no controlada entre el ciclo de luz natural y diversas fuentes artificiales, particularmente la emisión de luz azul de múltiples monitores.

Esta interacción genera escenarios de iluminación mixta complejos que sesgan la firma de color de la imagen captada por las cámaras. La problemática central es que esta mezcla de temperaturas de color afecta negativamente el desempeño de algoritmos críticos, haciendo necesario modelar correctamente la fuente de luz dominante para optimizar el Balance de Blancos Automático (AWB) o permitir que los sistemas de seguridad corrijan la dominante de color.

\section{Planteamiento del Problema}

\subsection{Contexto y Situación de la Realidad}

La situación problemática se ubica en el contexto de la Visión por Computador y el procesamiento de imágenes, específicamente en la oficina doméstica (\textit{Home Office}) de un programador. En este entorno ocurre una interacción dinámica y no controlada entre el ciclo de luz natural y diversas fuentes artificiales, particularmente la emisión de luz azul de múltiples monitores.

Esta interacción genera escenarios de iluminación mixta complejos que sesgan la firma de color de la imagen captada por las cámaras. La problemática central es que esta mezcla de temperaturas de color afecta negativamente el desempeño de algoritmos críticos, haciendo necesario modelar correctamente la fuente de luz dominante para optimizar el Balance de Blancos Automático (AWB) o permitir que los sistemas de seguridad corrijan la dominante de color.

\subsection{Caracterización del Objeto de Estudio}

El objeto de estudio es el entorno visual del puesto de trabajo registrado por la cámara, el cual presenta variaciones cíclicas durante el transcurso del día (mañana, tarde y noche).

El sistema caracteriza esta situación mediante variables extraídas con \textit{Machine Learning}:

\begin{description}
    \item[Variables de Entrada:] La luminosidad y el color de cada píxel, procesados para detectar qué tipo de luz predomina en la escena.
    \item[Fenómeno a Modelar:] La "firma de color" de la imagen, la cual se ve alterada por la mezcla de luces.
\end{description}

\subsection{Naturaleza de la Decisión (Diagnóstico)}

El problema se define como una tarea de Clasificación (Diagnóstico), donde se requiere determinar la categoría de la fuente de luz dominante en un instante dado.

Las alternativas de decisión mutuamente excluyentes establecidas para el modelo son:

\begin{itemize}
    \item \textbf{Clase 1:} Luz Natural (Sol/Cielo).
    \item \textbf{Clase 2:} Luz artificial.
    \item \textbf{Clase 3:} Luz Artificial Tipo Brillo de Pantallas.
    \item \textbf{Clase 4:} Mix.
\end{itemize}

\section{Diseño de la Arquitectura}

El objetivo es establecer una arquitectura de \textit{software} modular, escalable y reproducible que integre la adquisición de señales ópticas, la ingeniería de características estadísticas y la clasificación mediante algoritmos de \textit{Gradient Boosting}.

El sistema se conceptualiza como un \textit{Pipeline} de Procesamiento Secuencial dividido en tres capas lógicas: Capa de Adquisición (Hardware/Drivers), Capa de Abstracción de Datos (\textit{Feature Engineering}) y Capa de Inferencia (\textit{Machine Learning}).

\subsection{Hardware (Nivel Físico y Adquisición)}

Corresponde a la "Capa de Adquisición" y el "Nivel Físico". Es lo tangible y el puente directo con la realidad.

\begin{description}
    \item[Sensor/Dispositivo:] Webcam con sensor CMOS (encargada de recibir los fotones/luz).
    \item[Controladores:] Drivers (intermediarios entre el sensor y el sistema operativo).
    \item[Mecanismos de Control:] Bloqueo de ganancia automática y Balance de Blancos (AWB) a nivel de \textit{hardware/driver} para evitar alteraciones en la señal.
\end{description}

\subsection{Software (Lógica y Stack Tecnológico)}

Para garantizar la reproducibilidad científica del experimento y la estabilidad de los algoritmos de aprendizaje, se ha estandarizado el entorno de desarrollo sobre Python 3.13. La selección de librerías obedece a criterios de eficiencia computacional (vectorización) y robustez estadística. A continuación, se detalla la función de cada componente en la arquitectura:

\begin{description}
    \item[\texttt{opencv-python}:] Gestión de la adquisición de imagen desde la webcam y transformación matemática de espacios de color (BGR a CIELAB/HSV) para aislar la crominancia.
    \item[\texttt{numpy}:] Motor de cálculo matricial utilizado para vectorizar las imágenes y realizar operaciones aritméticas de alta velocidad sobre los canales de píxeles.
    \item[\texttt{scipy}:] Herramienta de estadística avanzada empleada para calcular el coeficiente de asimetría (\textit{skewness}) de los histogramas de luz, métrica clave para detectar fuentes LED.
    \item[\texttt{pandas}:] Estructuración del \textit{Dataset} Maestro, manejo de series temporales, limpieza de registros nulos y codificación numérica de las etiquetas de clase (\textit{Label Encoding}).
    \item[\texttt{scikit-learn}:] Librería base para el preprocesamiento de datos, responsable del escalado de variables (\textit{StandardScaler}) y la partición estratificada del conjunto de entrenamiento/prueba.
    \item[\texttt{xgboost}:] Implementación optimizada del algoritmo de \textit{Gradient Boosting}, utilizada como el clasificador principal por su alta precisión en datos tabulares complejos y no lineales.
    \item[\texttt{matplotlib} y \texttt{seaborn}:] Suite de visualización científica encargada de generar la matriz de confusión para evaluación de errores y los mapas de calor de correlación de variables.
\end{description}

\subsection{Flujo de Datos (Data Pipeline)}

La arquitectura sigue un flujo secuencial de cinco etapas, alineadas con las capas lógicas del diagrama de solución (Figura 1):

\begin{description}
    \item[Etapa 1: Nivel Físico (Entorno y Sensor)] \hfill \\
    Corresponde a la interacción radiométrica inicial. Las fuentes de luz emiten fotones que inciden sobre el sensor CMOS de la webcam.
    \begin{itemize}
        \item \textbf{Control:} En esta etapa se establece la restricción de \textit{hardware}: bloqueo de ganancia automática y balance de blancos (AWB) para evitar alteraciones en la señal de entrada.
    \end{itemize}

    \item[Etapa 2: Adquisición de Datos (Data Ingestion)] \hfill \\
    El sistema digitaliza la señal óptica. Mediante la librería \texttt{opencv-python}, se captura el flujo de video y se congela un fotograma \textit{Raw} en formato matricial RGB.

    \item[Etapa 3: Ingeniería de Características (Processing)] \hfill \\
    Es la fase de transformación matemática.
    \begin{itemize}
        \item \textbf{Transformación:} La matriz BGR se convierte a espacios CIELAB y HSV.
        \item \textbf{Reducción:} Se aplican operadores estadísticos (\texttt{numpy}/\texttt{scipy}) para colapsar la matriz de 2.7 millones de valores a un vector compacto de 9 variables predictoras.
        \item \textbf{Normalización:} Se aplica una estandarización \textit{Z-Score} para escalar las variables.
    \end{itemize}

    \item[Etapa 4: Inferencia (Intelligence)] \hfill \\
    El vector numérico procesado ingresa al modelo de Inteligencia Artificial. El algoritmo evalúa las características no lineales y calcula un \textit{array} de probabilidades para las cuatro clases posibles (Natural, Artificial, Pantalla, Mix).

    \item[Etapa 5: Aplicación y Decisión (Output)] \hfill \\
    La capa final interpreta el resultado matemático.
    \begin{itemize}
        \item \textbf{Decisión:} Se aplica una función \texttt{argmax} para seleccionar la etiqueta con mayor probabilidad.
        \item \textbf{Persistencia:} El sistema registra la etiqueta, la fecha y la confianza de la predicción en el archivo CSV (\texttt{dataset.csv}) para su posterior auditoría.
    \end{itemize}
\end{description}

\subsection{Arquitectura del Clasificador Multi-Categoria}

El sistema implementa una arquitectura jerarquica de clasificacion denominada \textbf{Multi-Category Classifier} que combina tres componentes principales para lograr una precision global del 98.97\%. Esta arquitectura sigue el paradigma de \textit{stacking} donde clasificadores binarios especializados alimentan a un meta-clasificador final.

% Definicion de estilos TikZ para el diagrama
\tikzset{
    inputbox/.style={rectangle, draw=blue!70, fill=blue!10, thick, minimum width=4cm, minimum height=0.8cm, text centered, font=\small},
    igranker/.style={rectangle, draw=orange!70, fill=orange!10, thick, minimum width=4cm, minimum height=1cm, text centered, font=\small},
    binarymodel/.style={rectangle, draw=green!70, fill=green!10, thick, minimum width=1.8cm, minimum height=1.2cm, text centered, font=\scriptsize},
    probbox/.style={rectangle, draw=purple!70, fill=purple!10, thick, minimum width=4.5cm, minimum height=0.8cm, text centered, font=\small},
    metaclass/.style={rectangle, draw=red!70, fill=red!10, thick, minimum width=4cm, minimum height=1cm, text centered, font=\small},
    outputbox/.style={rectangle, draw=black!70, fill=gray!10, thick, minimum width=3.5cm, minimum height=0.8cm, text centered, font=\small},
    arrow/.style={-{Stealth[length=2.5mm]}, thick}
}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=0.8cm]
        % Nodo de entrada
        \node[inputbox] (input) {\textbf{Datos de Entrada} $(X)$};

        % CategoryIGRanker
        \node[igranker, below=of input] (igranker) {\textbf{CategoryIGRanker}\\ (Seleccion de Features por IG)};

        % Clasificadores binarios
        \node[binarymodel, below left=1cm and 1.5cm of igranker] (m1) {\textbf{Modelo}\\ Natural};
        \node[binarymodel, below left=1cm and 0cm of igranker] (m2) {\textbf{Modelo}\\ Artificial};
        \node[binarymodel, below right=1cm and 0cm of igranker] (m3) {\textbf{Modelo}\\ Pantallas};
        \node[binarymodel, below right=1cm and 1.5cm of igranker] (m4) {\textbf{Modelo}\\ Mix};

        % Caja de probabilidades
        \node[probbox, below=2.8cm of igranker] (probs) {\textbf{Probabilidades por Categoria} $[P_1, P_2, P_3, P_4]$};

        % Meta-clasificador
        \node[metaclass, below=of probs] (meta) {\textbf{Meta-Clasificador}\\ (Logistic Regression Multinomial)};

        % Prediccion final
        \node[outputbox, below=of meta] (output) {\textbf{Prediccion Final}};

        % Flechas
        \draw[arrow] (input) -- (igranker);
        \draw[arrow] (igranker) -- (m1);
        \draw[arrow] (igranker) -- (m2);
        \draw[arrow] (igranker) -- (m3);
        \draw[arrow] (igranker) -- (m4);
        \draw[arrow] (m1) -- (probs);
        \draw[arrow] (m2) -- (probs);
        \draw[arrow] (m3) -- (probs);
        \draw[arrow] (m4) -- (probs);
        \draw[arrow] (probs) -- (meta);
        \draw[arrow] (meta) -- (output);

        % Etiquetas laterales
        \node[left=0.3cm of igranker, font=\scriptsize\itshape, text=gray] {Nivel 1};
        \node[left=0.3cm of m1, font=\scriptsize\itshape, text=gray] {Nivel 2};
        \node[left=0.3cm of meta, font=\scriptsize\itshape, text=gray] {Nivel 3};

    \end{tikzpicture}
    \caption{Arquitectura del Multi-Category Classifier. El flujo de datos atraviesa tres niveles: seleccion de caracteristicas por Ganancia de Informacion (IG), clasificadores binarios One-vs-Rest (Random Forest), y un meta-clasificador de ensamble (Logistic Regression multinomial).}
    \label{fig:multi_category_arch}
\end{figure}

\subsubsection{Componente 1: CategoryIGRanker (Seleccion de Caracteristicas)}

El \textbf{CategoryIGRanker} implementa un mecanismo de seleccion de caracteristicas basado en la \textbf{Ganancia de Informacion} (IG, \textit{Information Gain}) calculada de forma independiente para cada categoria. La Ganancia de Informacion mide cuanta incertidumbre sobre la clase objetivo reduce una caracteristica:

\begin{equation}
    IG(Y, X) = H(Y) - H(Y|X)
\end{equation}

donde $H(Y)$ representa la entropia de la variable objetivo (clase) y $H(Y|X)$ es la entropia condicional dado el valor de la caracteristica $X$.

Este componente realiza las siguientes operaciones:
\begin{itemize}
    \item Calcula la matriz de IG para cada par \textit{(feature, categoria)} utilizando el paradigma \textit{One-vs-Rest}.
    \item Genera un ranking de caracteristicas especifico para cada categoria.
    \item Selecciona las \textit{Top-K} caracteristicas mas informativas para cada modelo binario.
\end{itemize}

La Tabla \ref{tab:ig_matrix} presenta la matriz de Ganancia de Informacion obtenida en el experimento:

\begin{table}[H]
    \centering
    \caption{Matriz de Ganancia de Informacion (Features $\times$ Categorias)}
    \label{tab:ig_matrix}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        \textbf{Feature} & \textbf{Natural} & \textbf{Artificial} & \textbf{Pantallas} & \textbf{Mix} \\ \midrule
        \texttt{std\_v} & 0.329 & 0.382 & \textbf{0.571} & 0.359 \\
        \texttt{mean\_b} & 0.241 & 0.371 & \textbf{0.571} & 0.256 \\
        \texttt{skew\_v} & 0.375 & 0.455 & \textbf{0.569} & 0.415 \\
        \texttt{v\_95} & 0.337 & \textbf{0.513} & \textbf{0.570} & 0.389 \\ \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \small
        \item \textit{Nota:} Valores en negrita indican IG $> 0.5$ (alta discriminacion).
    \end{tablenotes}
\end{table}

\subsubsection{Componente 2: Clasificadores Binarios por Categoria (One-vs-Rest Random Forest)}

El segundo nivel de la arquitectura consta de \textbf{cuatro clasificadores binarios independientes}, cada uno implementado mediante un modelo \textbf{Random Forest}. Estos clasificadores siguen el paradigma \textit{One-vs-Rest} (OvR), donde cada modelo aprende a distinguir una categoria especifica del resto:

\begin{itemize}
    \item \textbf{Modelo Natural:} Distingue muestras de luz natural vs. (artificial $\cup$ pantallas $\cup$ mix).
    \item \textbf{Modelo Artificial:} Distingue muestras de luz artificial vs. el resto.
    \item \textbf{Modelo Pantallas:} Distingue muestras de pantallas vs. el resto.
    \item \textbf{Modelo Mix:} Distingue muestras de iluminacion mixta vs. el resto.
\end{itemize}

Cada modelo Random Forest utiliza las \textit{Top-K} caracteristicas segun el ranking IG calculado por el CategoryIGRanker para su categoria correspondiente. La configuracion optima establecida es:

\begin{table}[H]
    \centering
    \caption{Configuracion de los Clasificadores Binarios Random Forest}
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Parametro} & \textbf{Valor} \\ \midrule
        \texttt{n\_estimators} & 100 \\
        \texttt{criterion} & gini \\
        \texttt{max\_depth} & None (sin limite) \\
        \texttt{top\_k} & 4 (todas las features disponibles) \\ \bottomrule
    \end{tabular}
\end{table}

Cada clasificador binario genera una \textbf{probabilidad de pertenencia} $P_i \in [0, 1]$ para su categoria correspondiente, resultando en un vector de probabilidades $\mathbf{P} = [P_{\text{natural}}, P_{\text{artificial}}, P_{\text{pantallas}}, P_{\text{mix}}]$.

\subsubsection{Componente 3: Meta-Clasificador (Logistic Regression Multinomial)}

El tercer y ultimo nivel implementa un \textbf{meta-clasificador de ensamble} basado en \textbf{Regresion Logistica Multinomial}. Este componente recibe como entrada el vector de probabilidades generado por los clasificadores binarios y produce la prediccion final multi-clase.

La Regresion Logistica Multinomial modela la probabilidad de cada clase mediante la funcion \textit{softmax}:

\begin{equation}
    P(Y = k | \mathbf{P}) = \frac{e^{\mathbf{w}_k^T \mathbf{P} + b_k}}{\sum_{j=1}^{4} e^{\mathbf{w}_j^T \mathbf{P} + b_j}}
\end{equation}

donde $\mathbf{w}_k$ y $b_k$ son los pesos y sesgo aprendidos para la clase $k$.

El meta-clasificador aporta las siguientes ventajas:
\begin{itemize}
    \item \textbf{Calibracion de probabilidades:} Corrige posibles desbalances en las salidas de los modelos binarios.
    \item \textbf{Resolucion de conflictos:} Cuando multiples clasificadores binarios indican alta probabilidad, pondera inteligentemente.
    \item \textbf{Regularizacion:} Evita sobreajuste mediante penalizacion L2 implicita.
\end{itemize}

\subsubsection{Flujo de Trabajo Completo}

El proceso de inferencia para una nueva muestra sigue el siguiente flujo secuencial:

\begin{enumerate}
    \item \textbf{Entrada:} Se recibe un vector de caracteristicas $\mathbf{X} = [\texttt{std\_v}, \texttt{mean\_b}, \texttt{skew\_v}, \texttt{v\_95}]$.

    \item \textbf{Seleccion de Features:} El CategoryIGRanker selecciona las caracteristicas optimas para cada modelo binario segun el ranking IG precalculado.

    \item \textbf{Clasificacion Binaria:} Cada uno de los 4 modelos Random Forest procesa la muestra en paralelo, generando una probabilidad de pertenencia:
    \begin{equation}
        P_i = \text{RandomForest}_i(\mathbf{X}_{\text{top-k}}), \quad i \in \{\text{natural}, \text{artificial}, \text{pantallas}, \text{mix}\}
    \end{equation}

    \item \textbf{Ensamble:} El vector de probabilidades $\mathbf{P} = [P_1, P_2, P_3, P_4]$ alimenta al meta-clasificador.

    \item \textbf{Prediccion:} La Regresion Logistica Multinomial calcula las probabilidades finales calibradas y retorna la clase con maxima probabilidad:
    \begin{equation}
        \hat{y} = \arg\max_k P(Y = k | \mathbf{P})
    \end{equation}

    \item \textbf{Modo de Precision (opcional):} Si la probabilidad maxima esta por debajo de un umbral configurable $\tau$ (por defecto $\tau = 0.7$), el sistema retorna ``no\_decidido'' para evitar clasificaciones inciertas.
\end{enumerate}

Esta arquitectura jerarquica logro una precision del \textbf{98.97\%} en el conjunto de prueba, con clasificacion perfecta (100\%) para las categorias \textit{pantallas} y \textit{artificial}, validando la efectividad del enfoque de clasificadores especializados por categoria.

\section{Diseño del Experimento}

\subsection{Estrategia de Etiquetado: EX-ANTE}
Se optó por el enfoque \textit{EX-ANTE}, el cual implica que el etiquetado de la clase (la variable dependiente) se define antes de iniciar la captura de datos.

\subsection{Fase de Identificación de Categorías}
El primer paso del experimento consistió en identificar las categorías a diagnosticar. Se definieron cuatro clases que representan la variable objetivo:

\begin{itemize}
    \item \textbf{Clase 1:} Luz Natural (Sol/Cielo).
    \item \textbf{Clase 2:} Luz artificial.
    \item \textbf{Clase 3:} Luz Artificial Tipo Brillo de Pantallas.
    \item \textbf{Clase 4:} Mix.
\end{itemize}

\subsection{Preparación del Escenario (Control de Variables)}
Para cada sesión de captura, se procedió a preparar el escenario necesario asegurando que la categoría específica se encuentre presente de manera dominante.

\begin{description}
    \item[Configuración Escenario 1 (Natural):] Se abrieron cortinas y/o persianas y se apagaron todas las fuentes artificiales.
    \item[Configuración Escenario 2 (Artificial):] Se cerraron persianas, se encendieron las luces de techo y se apagaron monitores.
    \item[Configuración Escenario 3 (Pantallas):] Se generó oscuridad total ambiental y se encendieron los monitores con contenido de trabajo estándar.
    \item[Configuración Escenario 4 (Mix):] Se abrieron cortinas y/o persianas y se encendieron todas las fuentes artificiales.
\end{description}

\subsection{Proceso de Muestreo}
Una vez configurado el escenario físico y asignada la etiqueta correspondiente en el \textit{software} (\texttt{recolector.py}), se procedió al proceso de muestreo.

\begin{description}
    \item[Protocolo:] Se ejecutaron ráfagas automatizadas de 1000 instancias (fotografías) por sesión.
    \item[Temporalidad:] Se estableció un intervalo de captura ($t = 0.5s$) para capturar micro-variaciones temporales de la luz.
    \item[Segmentación:] Dado que la imagen completa es la señal, no se requirió segmentación espacial compleja, sino la extracción de la matriz completa de píxeles.
\end{description}

\section{DAQ (Adquisición de Datos)}

\subsection{Instrumentación y Configuración del Sensor}
En esta etapa se procedió a la captura de los datos utilizando los sensores definidos en la arquitectura. El instrumento principal es una Cámara Web (\textit{Webcam}), la cual opera como un sensor óptico matricial encargado de registrar el entorno del programador.

A diferencia de un sensor puntual (como una fotocelda), este dispositivo permite capturar una matriz de señales que contiene información simultánea sobre la luminosidad y el color de cada píxel, variables críticas para detectar qué tipo de luz predomina en la escena.

\subsection{Ejecución del Muestreo (Protocolo Ex-Ante)}
La adquisición de datos se realizó bajo una estrategia \textit{Ex-Ante}. El procedimiento ejecutado fue el siguiente:

\begin{description}
    \item[Preparación del Escenario:] Antes de iniciar la captura, se preparó el entorno físico para asegurar que la categoría a diagnosticar se encontrara presente de forma dominante.
    \item[Etiquetado en Origen:] Se asignó la etiqueta de la clase correspondiente en el \textit{software} recolector antes de iniciar la grabación, garantizando que cada instancia de datos naciera ya clasificada.
    \item[Captura de Instancias:] Se procedió al proceso de muestreo, registrando ráfagas de imágenes en intervalos de tiempo definidos para capturar las variaciones del ciclo de vida del ambiente luminoso (mañana, tarde, noche).
\end{description}

\subsection{Verificación de Calidad de la Señal}
Durante el proceso de adquisición, se verificó la calidad de las señales captadas para asegurar la integridad del \textit{dataset}.

\begin{description}
    \item[Validación:] Se implementaron controles en el \textit{script} de captura para descartar imágenes corruptas, negras (fallo de sensor) o totalmente saturadas (sobreexposición extrema) que no aportan información válida sobre la firma de color.
    \item[Re-muestreo:] En los casos donde la variación ambiental fue insuficiente o el sensor presenta latencia, se procedió a volver a ejecutar el proceso de muestreo para garantizar un volumen de datos estadísticamente significativo.
\end{description}

\subsection{Resultado de la Etapa}
El resultado de esta fase es un conjunto de instancias de datos etiquetados (imágenes \textit{raw}) que reflejan fielmente la interacción dinámica entre el ciclo de luz natural y las fuentes artificiales, listas para ser transformadas en la siguiente etapa de Creación del \textit{DataSet}.

% --- BLOQUE DE FIGURAS ---
% Nota: Reemplaza 'example-image' con tus archivos reales (ej. figura2.png)

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{example-image}
    \caption{Escenario experimental bajo iluminación predominante de pantallas.}
    \label{fig:escenario_pantallas}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{example-image-a}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{example-image-b}
    \end{minipage}
    \caption{Escenario experimental bajo iluminación predominante de luz natural.}
    \label{fig:escenario_natural}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{example-image}
    \caption{Escenario experimental bajo iluminación predominante de luz artificial.}
    \label{fig:escenario_artificial}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{example-image-c}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{example-image}
    \end{minipage}
    \caption{Escenario experimental bajo iluminación mixta.}
    \label{fig:escenario_mixta}
\end{figure}


\section{Creación de DataSet}

\subsection{Transformación de Señal a Dato Estructurado}
En esta fase se procede a transformar la señal cruda (imágenes captadas por el sensor) en un \textit{dataset} estructurado apto para el modelado matemático.
El sistema no almacena la matriz de píxeles completa (lo cual generaría una alta dimensionalidad innecesaria), sino que procesa la luminosidad y el color de cada píxel para extraer un vector de características representativas. Este proceso convierte datos no estructurados (imágenes .jpg) en datos tabulares numéricos.

\subsection{Generación desde Instancias Etiquetadas}
El \textit{dataset} se construye consolidando las instancias de datos previamente etiquetadas durante la fase de Adquisición (DAQ). Se integran las sesiones de captura de los cuatro escenarios (Luz Natural, Artificial, Pantalla y Mix) en un único archivo maestro (formato CSV).

\subsection{Estructura del Dataset Final}
El archivo resultante se organiza matricialmente donde cada fila representa una observación (instancia temporal) y cada columna representa una variable o atributo extraído del análisis de la "firma de color".

\section{Descripción de Datos}

\subsection{Composición y Volumen}
El conjunto de datos maestro (\texttt{DATASET\_MAESTRO\_COMPLETO.csv}) se construyó mediante sesiones de captura controlada, acumulando un total de $N = 8,600$ observaciones válidas tras el proceso de limpieza. Cada registro representa un intervalo de tiempo de 0.5 segundos de exposición, garantizando la captura de micro-variaciones lumínicas.

La distribución de clases presenta un balance controlado, diseñado para evitar el sesgo del clasificador hacia una categoría mayoritaria:

\begin{table}[H]
    \centering
    \caption{Composición y volumen de datos}
    \label{tab:composicion_datos}
    \begin{tabular}{@{}lccl@{}}
        \toprule
        \textbf{Etiqueta de Clase} & \textbf{Cantidad ($n$)} & \textbf{Prop. (\%)} & \textbf{Descripción del Escenario} \\ \midrule
        0 - Artificial & 2,300 & 26,7\% & Iluminación LED/Fluorescente cenital. \\
        1 - Mixta & 2,000 & 23,3\% & Superposición: Ventana + Techo + Monitor. \\
        2 - Natural & 2,000 & 23,3\% & Luz diurna (Soleado/Nublado) sin fuentes. \\
        3 - Pantallas & 2,300 & 26,7\% & Entorno oscuro iluminado por monitor. \\ \midrule
        \textbf{TOTAL} & \textbf{8,600} & \textbf{100\%} & \\ \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{example-image} % Reemplazar con Figura 8 (Matriz o EDA)
    \caption{Análisis EDA. La matriz presenta una diagonal principal fuertemente marcada.}
    \label{fig:eda}
\end{figure}

\subsubsection*{Interpretación Técnica:}
\begin{description}
    \item[Robustez en Clases Puras:] El modelo no comete errores al identificar "Pantallas". Esto valida que la firma de asimetría (\texttt{skew\_v} > 4.0) es un discriminante determinista que no deja lugar a ambigüedad.
    \item[Resolución del Conflicto "Mixto":] Existía la hipótesis de riesgo de que la clase "Mixta" fuera confundida masivamente con "Natural". Sin embargo, la matriz muestra que el error es marginal ($<2\%$). Esto indica que el modelo ha aprendido a detectar la saturación suavizada y la temperatura de color intermedia, separándolas exitosamente de una fuente natural pura.
\end{description}

\subsection{Diccionario de Atributos (Feature Space)}
Cada instancia está descrita por un vector de 12 dimensiones, compuesto por variables físicas directas y variables sintéticas de ingeniería:

\textbf{Atributos Espectrales (Color):}
\begin{itemize}
    \item \texttt{mean\_h} (Matiz/Hue): Tono cromático principal.
    \item \texttt{mean\_s} (Saturación): Pureza del color.
    \item \texttt{mean\_a} (Canal a* CIELAB): Eje Verde-Rojo.
    \item \texttt{mean\_b} (Canal b* CIELAB): Eje Azul-Amarillo (\textit{Crítico para detectar pantallas}).
\end{itemize}

\textbf{Atributos de Intensidad y Contraste:}
\begin{itemize}
    \item \texttt{mean\_v} (Brillo promedio HSV): Luminancia global.
    \item \texttt{std\_v} (Desviación estándar del Brillo): Variabilidad de la luz (Sombras vs. Luz plana).
    \item \texttt{std\_l} (Desviación estándar de Luminancia HSL): Textura percibida.
    \item \texttt{v\_95} (Percentil 95): Intensidad máxima robusta (Teoría Retinex).
\end{itemize}

\textbf{Atributos Morfológicos:}
\begin{itemize}
    \item \texttt{skew\_v} (Asimetría del histograma): Forma de la distribución de luz (\textit{Crítico para detectar fuentes artificiales}).
\end{itemize}

\textbf{Atributos Sintéticas (Feature Engineering):}
\begin{itemize}
    \item \texttt{v\_range}: Rango dinámico efectivo.
    \item \texttt{h\_s\_product}: Potencia cromática (filtra blancos neutros).
    \item \texttt{v\_skew\_abs}: Magnitud absoluta de la asimetría.
\end{itemize}

\begin{table}[H]
    \centering
    \caption{Comportamiento de Atributos por Clase}
    \label{tab:variables_roles}
    \small
    \begin{tabular}{@{}lp{1.5cm}p{3cm}p{3cm}p{3cm}@{}}
        \toprule
        \textbf{Variable} & \textbf{Rol} & \textbf{Luz Natural} & \textbf{Luz Artificial} & \textbf{Pantallas} \\ \midrule
        \texttt{mean\_b} & Color & Negativo (Azul) \newline Rango: -15 a -2 & Positivo Alto (Cálido) \newline Rango: +5 a +15 & Positivo Bajo (Estable) \newline Rango: +1.5 a +3.5 \\ \midrule
        \texttt{skew\_v} & Forma & Baja \newline Valor: $< 1.0$ & Alta \newline Valor: $> 3.0$ & Baja \newline Valor: $< 1.0$ \\ \midrule
        \texttt{std\_v} & Sombras & Baja (Suave) \newline Valor: $< 35$ & Variable \newline (Depende del foco) & Muy Alta (Contraste) \newline Valor: $> 35$ \\ \midrule
        \texttt{v\_95} & Intensidad & Alta (Día) & Media/Alta & Variable \\ \bottomrule
    \end{tabular}
\end{table}

\subsection{Análisis Estadístico Diferencial}
Al analizar los datos, encontramos diferencias claras entre los tipos de luz que permiten a nuestro sistema clasificarlos correctamente.

\subsubsection*{A. Cómo identificar las Pantallas (\texttt{mean\_h} y \texttt{skew\_v})}
La luz de las pantallas es la más fácil de distinguir porque se comporta de forma muy diferente a las demás.

\begin{enumerate}
    \item \textbf{El color es muy estable:} La luz del sol cambia mucho según el clima, pero la luz de un monitor casi siempre tiene el mismo tono. En la Figura \ref{fig:hist_matiz} se observa cómo la curva roja (pantallas) es alta y delgada.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{example-image} % Reemplazar con Figura 9
        \caption{Histograma de Matiz. El pico rojo muestra estabilidad de color en pantallas.}
        \label{fig:hist_matiz}
    \end{figure}

    \item \textbf{La forma de la luz es única:} Las pantallas suelen ser un punto brillante en un cuarto oscuro, creando una asimetría alta.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{example-image} % Reemplazar con Figura 10
        \caption{Histograma de Asimetría. Las pantallas (rojo) se separan del resto.}
        \label{fig:hist_asimetria}
    \end{figure}
\end{enumerate}

\subsubsection*{B. Diferencia entre Luz Natural y Artificial}
Aunque parecen iguales, el eje Azul-Amarillo (canal $b^*$) las distingue. La Luz Artificial es estable (verde en Figura \ref{fig:cajas_b}), mientras que la Natural (azul) es variable y fría.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{example-image} % Reemplazar con Figura 11
    \caption{Gráfico de cajas del canal $b^*$. Diferencia clara entre artificial y natural.}
    \label{fig:cajas_b}
\end{figure}

\subsubsection*{C. Luz Mixta}
Confirmamos que la clase "Mixta" es el promedio de las otras, ubicándose matemáticamente justo en el medio de la luz natural y artificial.

\subsection{Análisis de Ganancia de Información}

Para cuantificar la capacidad discriminativa de cada atributo, se calculó la Ganancia de Información (IG) de las cuatro características principales respecto a cada categoría de luz. Este análisis permite identificar qué variables aportan mayor valor predictivo para la clasificación.

\subsubsection*{Matriz de Ganancia de Información por Categoría}

La Tabla \ref{tab:ig_matrix} presenta la matriz completa de IG, donde cada celda representa la reducción de entropía que aporta el atributo (fila) para distinguir la categoría específica (columna) del resto de clases.

\begin{table}[H]
    \centering
    \caption{Matriz de Ganancia de Información (Atributos $\times$ Categorías)}
    \label{tab:ig_matrix}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        \textbf{Atributo} & \textbf{Natural} & \textbf{Artificial} & \textbf{Pantallas} & \textbf{Mix} \\ \midrule
        \texttt{std\_v}   & 0.329 & 0.382 & 0.571 & 0.359 \\
        \texttt{mean\_b}  & 0.241 & 0.371 & 0.571 & 0.256 \\
        \texttt{skew\_v}  & 0.375 & 0.455 & 0.569 & 0.415 \\
        \texttt{v\_95}    & 0.337 & 0.513 & 0.570 & 0.389 \\ \bottomrule
    \end{tabular}
\end{table}

\subsubsection*{Ranking Global de Atributos}

La Tabla \ref{tab:ig_ranking} muestra el ranking global de atributos, calculado como el promedio ponderado de la IG a través de todas las categorías. Este ranking fundamenta la selección de características para el modelo final.

\begin{table}[H]
    \centering
    \caption{Ranking Global de Atributos por Ganancia de Información}
    \label{tab:ig_ranking}
    \begin{tabular}{@{}clc@{}}
        \toprule
        \textbf{Ranking} & \textbf{Atributo} & \textbf{IG Global} \\ \midrule
        1 & \texttt{skew\_v}  & 0.454 \\
        2 & \texttt{v\_95}    & 0.452 \\
        3 & \texttt{std\_v}   & 0.410 \\
        4 & \texttt{mean\_b}  & 0.360 \\ \bottomrule
    \end{tabular}
\end{table}

\subsubsection*{Interpretación de los Resultados}

\begin{description}
    \item[\texttt{skew\_v} (Asimetría del Brillo):] Ocupa el primer lugar global (IG = 0.454) debido a su capacidad para detectar distribuciones asimétricas de luz. Las fuentes puntuales (pantallas, focos LED) generan histogramas con cola larga hacia valores altos, mientras que la luz natural difusa produce distribuciones más simétricas.

    \item[\texttt{v\_95} (Percentil 95 del Brillo):] Con IG = 0.452, este atributo captura la intensidad máxima robusta de la escena. Es particularmente efectivo para distinguir ``Artificial'' (IG = 0.513), donde los focos LED generan zonas de alta luminancia concentrada.

    \item[\texttt{std\_v} (Desviación Estándar del Brillo):] Mide la variabilidad de la luz en la escena. Un valor alto indica alto contraste (sombras marcadas), característico de fuentes direccionales.

    \item[\texttt{mean\_b} (Canal $b^*$ CIELAB):] Representa el eje Azul-Amarillo del espacio perceptual. Aunque tiene la IG global más baja (0.360), es crítico para diferenciar la temperatura de color: valores negativos indican dominante azul (natural/pantallas) y positivos indican dominante cálida (artificial).
\end{description}

\subsubsection*{Fenómeno de Alta Discriminabilidad en Pantallas}

Un hallazgo notable es que la categoría ``Pantallas'' presenta valores de IG superiores a 0.57 para \textit{todos} los atributos analizados. Este fenómeno se explica por la naturaleza física única de esta fuente de luz:

\begin{enumerate}
    \item \textbf{Emisión Controlada:} Los monitores LCD/LED emiten luz con espectro y potencia constantes, a diferencia de la variabilidad del sol o la heterogeneidad de luminarias domésticas.

    \item \textbf{Contraste Ambiental Extremo:} El escenario ``Pantallas'' implica un entorno oscuro con una única fuente brillante, generando distribuciones estadísticas altamente características.

    \item \textbf{Firma Espectral Distintiva:} La emisión de luz azul (pico en 450-470 nm) de los monitores produce una combinación única de valores en \texttt{mean\_b} y \texttt{skew\_v} que no se replica en ninguna otra categoría.
\end{enumerate}

Este resultado valida la hipótesis de que las pantallas constituyen la clase más fácilmente separable del problema, lo cual se confirma posteriormente con la precisión del 100\% obtenida por los clasificadores en esta categoría.

\section{Preparación de Datos}
El objetivo es transformar los datos ``crudos'' en un conjunto limpio y listo para el entrenamiento.

\subsection{Limpieza de Datos}
\begin{itemize}
    \item \textbf{Eliminación de Duplicados:} Se borraron datos repetidos por congelamiento del sensor.
    \item \textbf{Filtrado de Ruido:} Se eliminaron los valores extremos (1\% superior e inferior) para quitar destellos o fallos.
\end{itemize}

\subsection{Creación de Nuevas Variables (Ingeniería de Características)}
\begin{itemize}
    \item \textbf{Rango Dinámico (\texttt{v\_range}):} Mide el contraste (Pantalla vs. Natural).
    \item \textbf{Potencia de Color (\texttt{h\_s\_product}):} Combina tono e intensidad para separar luz artificial de luz neutra.
    \item \textbf{Forma de la Luz (\texttt{v\_skew\_abs}):} Útil para detectar focos puntuales.
\end{itemize}

\subsection{Transformación Final}
Se adaptaron los datos para XGBoost mediante \textit{Label Encoding} (0-3) y escalado \textit{StandardScaler} para normalizar las magnitudes de las variables.

\section{Modelado}
Se entrenaron cuatro algoritmos para diferenciar los tipos de luz, probando desde métodos simples hasta avanzados.

\subsection{Selección de los Modelos}
\begin{description}
    \item[KNN (K-Vecinos Más Cercanos):] Clasifica según la similitud con ejemplos cercanos.
    \item[SVM (Máquinas de Vectores de Soporte):] Dibuja fronteras matemáticas para separar grupos.
    \item[Random Forest:] Crea múltiples árboles de decisión y vota por la mayoría. Robusto.
    \item[XGBoost:] Construye árboles secuencialmente para corregir errores previos. Alta precisión.
\end{description}

\subsection{Estrategia de Entrenamiento}
\begin{itemize}
    \item \textbf{División de Datos (80/20):} 80\% entrenamiento, 20\% prueba (blind test).
    \item \textbf{Validación Cruzada:} 5 iteraciones para garantizar estabilidad (promedio de 5 intentos).
\end{itemize}

\subsection{Ajuste de los Modelos}
\begin{itemize}
    \item \textbf{Random Forest:} 100 árboles, profundidad libre.
    \item \textbf{XGBoost:} Tasa de aprendizaje lenta (0.1) para evitar memorización.
\end{itemize}

\section{Optimización de Parámetros}
El objetivo final fue maximizar el \textbf{Valor Predictivo Positivo (VPP)} para reducir Falsos Positivos, críticos en entornos de \textit{Home Office}. Se utilizó \textit{Grid Search} con validación cruzada.

\subsection{Resultados de la Optimización}

\begin{table}[H]
    \centering
    \caption{Configuración Óptima para Random Forest}
    \begin{tabular}{@{}llp{6cm}@{}}
        \toprule
        \textbf{Parámetro} & \textbf{Valor} & \textbf{Impacto en VPP} \\ \midrule
        n\_estimators & 100 & Estabiliza el voto, reduciendo ruido. \\
        criterion & 'gini' & Maximiza la pureza de los nodos. \\
        max\_depth & None & Captura patrones sutiles ("Mixta"). \\ \bottomrule
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Configuración Óptima para XGBoost}
    \begin{tabular}{@{}llp{6cm}@{}}
        \toprule
        \textbf{Parámetro} & \textbf{Valor} & \textbf{Impacto en VPP} \\ \midrule
        learning\_rate & 0.1 & Evita memorización de errores. \\
        max\_depth & 3 & Restringe complejidad (evita ruido). \\ \bottomrule
    \end{tabular}
\end{table}

\subsection{Conclusión de la Etapa}
El modelo final (\textbf{Random Forest}) logró un VPP del \textbf{100\%} para "Pantallas" y "Artificial", y superior al 98\% para "Natural" y "Mixta", garantizando alta confiabilidad.

\section{Resultados}

\subsection{Evaluación Comparativa de Desempeño}
Random Forest alcanzó el mayor rendimiento global (\textbf{98.97\%}), seguido de KNN (98.90\%). SVM obtuvo el desempeño más bajo (95.07\%), demostrando dificultades con fronteras lineales.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{example-image} % Reemplazar con Figura 12
    \caption{Comparativa de exactitud (Accuracy) de los cuatro modelos.}
    \label{fig:comparativa_modelos}
\end{figure}

\subsection{Análisis de Errores}
\begin{itemize}
    \item \textbf{Detección Perfecta de Pantallas:} 100\% de precisión gracias a la asimetría del histograma.
    \item \textbf{Confusión Natural-Mixta:} Pequeño error esperado debido a la similitud física en ciertas horas del día.
    \item \textbf{Debilidad de SVM:} Mayor dispersión de errores, confirmando su inferioridad ante métodos de ensamble.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{example-image} % Reemplazar con Figura 13
    \caption{Matrices de confusión normalizadas.}
    \label{fig:matrices_confusion}
\end{figure}

\subsection{Selección del Modelo Final}
Se selecciona \textbf{Random Forest} por su estabilidad operativa, insensibilidad al escalado y robustez en la votación por mayoría (Bagging).

\subsection{Análisis del Modo de Precisión}
\label{subsec:precision-mode}

El clasificador implementa un \textbf{modo de precisión} que permite ajustar el umbral de confianza para la toma de decisiones. Este mecanismo introduce un compromiso controlable entre la precisión de las predicciones y la cobertura del sistema.

\subsubsection{Concepto del Modo de Precisión}

En el modo estándar, el clasificador asigna cada muestra a la clase con mayor probabilidad predicha. El modo de precisión introduce un umbral de confianza $\tau$ tal que:

\begin{equation}
    \text{Decisión} =
    \begin{cases}
        \arg\max_c P(c|x) & \text{si } \max_c P(c|x) \geq \tau \\
        \text{No Decidido} & \text{en caso contrario}
    \end{cases}
\end{equation}

donde $P(c|x)$ representa la probabilidad de la clase $c$ dada la observación $x$. Las muestras clasificadas como ``No Decidido'' requieren revisión adicional, pero las decisiones tomadas presentan mayor confiabilidad.

\subsubsection{Comparación de Umbrales}

La Tabla~\ref{tab:threshold-comparison} presenta el impacto de diferentes umbrales de confianza sobre las métricas de rendimiento del sistema.

\begin{table}[H]
    \centering
    \caption{Comparación de métricas según umbral de confianza}
    \label{tab:threshold-comparison}
    \begin{tabular}{@{}cccccc@{}}
        \toprule
        \textbf{Umbral} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Decididos} & \textbf{No Decididos} & \textbf{\% No Decidido} \\
        \midrule
        0.5 & 98.90\% & 98.90\% & 1,458 & 2 & 0.14\% \\
        0.6 & 98.90\% & 98.90\% & 1,457 & 3 & 0.21\% \\
        0.7 & 98.97\% & 98.97\% & 1,456 & 4 & 0.27\% \\
        0.8 & 99.10\% & 99.10\% & 1,450 & 10 & 0.68\% \\
        0.9 & 99.37\% & 99.37\% & 1,439 & 21 & 1.44\% \\
        \bottomrule
    \end{tabular}
\end{table}

Se observa una relación directa entre el umbral de confianza y la precisión del sistema: al incrementar $\tau$ de 0.5 a 0.9, la accuracy mejora de 98.90\% a 99.37\%, representando una reducción del 43\% en la tasa de error.

\subsubsection{Impacto en la Matriz de Confusión}

El análisis de las matrices de confusión bajo diferentes umbrales revela que los errores eliminados corresponden predominantemente a confusiones entre las clases \texttt{natural} y \texttt{mix}. Esto se explica por:

\begin{itemize}
    \item La iluminación \texttt{mix} representa una combinación de fuentes naturales y artificiales
    \item Las condiciones de transición (amanecer, atardecer con iluminación interior) generan características ambiguas
    \item El modelo asigna probabilidades intermedias a estos casos límite
\end{itemize}

\subsubsection{Recomendaciones de Configuración}

La Tabla~\ref{tab:threshold-recommendations} presenta las configuraciones recomendadas según el contexto de aplicación.

\begin{table}[H]
    \centering
    \caption{Recomendaciones de umbral según caso de uso}
    \label{tab:threshold-recommendations}
    \begin{tabular}{@{}lcp{5.5cm}@{}}
        \toprule
        \textbf{Caso de Uso} & \textbf{Umbral} & \textbf{Justificación} \\
        \midrule
        Aplicación general & 0.7 & Balance óptimo entre precisión (98.97\%) y cobertura (99.73\%). \\
        Sistema crítico & 0.8--0.9 & Máxima precisión para aplicaciones donde los errores tienen alto costo. \\
        Alta cobertura & 0.5--0.6 & Minimiza casos no decididos manteniendo precisión aceptable. \\
        \bottomrule
    \end{tabular}
\end{table}

\section{Conclusiones}
\begin{enumerate}
    \item \textbf{Viabilidad del Hardware de Bajo Costo:} Una webcam estándar y el procesamiento estadístico en espacios de color HSV y CIELAB validan la hipótesis de bajo costo propuesta por Botero et al. \cite{lao}, logrando una precisión del \textbf{98.97\%}.

    \item \textbf{Eficacia del Criterio de Ganancia de Información:} La metodología de selección de atributos mediante IG permitió identificar que \texttt{skew\_v} (IG = 0.454) y \texttt{v\_95} (IG = 0.452) son los predictores más potentes. Este análisis reduce la dimensionalidad del problema y mejora la interpretabilidad física del modelo.

    \item \textbf{Superioridad de la Arquitectura Multi-Categoría:} El clasificador One-vs-Rest con Meta-Ensemble supera a los modelos monolíticos al especializar cada detector en las características de mayor IG para cada clase. Random Forest (98.97\%) superó a SVM (95.07\%), validando la eficacia de los métodos de ensamble para datos tabulares de sensores.

    \item \textbf{Patrones Físicos Distintivos Validados:} Se confirmaron marcadores espectrales únicos para cada categoría:
    \begin{itemize}
        \item Pantallas: IG $>$ 0.57 para \textit{todos} los atributos (detección determinista al 100\%).
        \item Artificial: Alta discriminación en \texttt{v\_95} (IG = 0.513) por focos LED concentrados.
        \item Natural: Distribución más uniforme de IG, requiere combinación de múltiples atributos.
        \item Mix: Comportamiento intermedio, justifica el uso del meta-clasificador.
    \end{itemize}

    \item \textbf{Optimización del Modo de Precisión:} La calibración de umbrales por clase permitió incrementar la precisión hasta \textbf{99.37\%} (umbral $\tau = 0.9$) con solo 1.44\% de casos no decididos. El umbral óptimo recomendado es $\tau = 0.7$ para balance entre precisión y cobertura.

    \item \textbf{Solución Integral al Problema del Home Office:} El sistema desarrollado permite:
    \begin{itemize}
        \item Corregir automatismos fallidos de Balance de Blancos (AWB).
        \item Prevenir fatiga visual mediante alertas de exposición prolongada a luz azul.
        \item Integrar con sistemas IoT para compensación lumínica activa.
    \end{itemize}
\end{enumerate}

\section{Recomendaciones}
\begin{itemize}
    \item \textbf{Integración IoT:} Evolucionar hacia un control activo de luces inteligentes (Philips Hue/Xiaomi) para compensar contrastes dañinos automáticamente.
    \item \textbf{Ampliación Estacional:} Recolectar datos en invierno/verano para asegurar generalización ante variaciones solares anuales.
\end{itemize}

\begin{thebibliography}{9}

\bibitem{rhudy}
M. B. Rhudy, S. K. Dolan, C. Mellob, and N. Greenauer, "Indoor and outdoor classification using light measurements and machine learning," \textit{Appl. Artif. Intell.}, vol. 36, no. 1, p. e2012001, 2022.

\bibitem{mestiraihi}
M. Al Mestiraihi, H. Abuella, and S. Ekin, "Indoor occupancy estimation using visible light sensing (VLS) system," in \textit{Proc. IEEE Int. Conf. Commun. (ICC)}, Kansas City, MO, USA, 2018, pp. 1–6.

\bibitem{lao}
P. Lao, Q. Liu, Y. Ding, Y. Wang, Y. Li, and M. Li, "Urban nighttime light source classification using ISO photography and XGBoost," \textit{Remote Sens.}, vol. 13, no. 16, p. 3273, 2021.

\bibitem{ishii}
H. Ishii, "A machine learning approach for light source classification: Performance improvement of PDD compensator," in \textit{Proc. Int. Conf. Adv. Mechatronic Syst.}, Kusatsu, Japan, 2019, pp. 1–6.

\end{thebibliography}

\newpage
\onecolumn  
\section{Anexo: Implementación del Código Fuente}

% Configuración visual para el código (Courier, fondo blanco, borde)
\lstset{
    language=Python,
    backgroundcolor=\color{white},   
    commentstyle=\color{green!60!black},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{gray},
    stringstyle=\color{purple},
    basicstyle=\fontfamily{pcr}\selectfont\scriptsize, % Courier New tamaño 8
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=t,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single,                    % Cuadro alrededor de cada función
    rulecolor=\color{black}
}

El código fuente completo, los archivos de audio procesados y el dataset generado en este trabajo se encuentran disponibles en el siguiente repositorio:

\begin{center}
    \url{https://github.com/orlando-kuan/webcam-light-sensor}
\end{center}


A continuación se presenta el código fuente desarrollado en Python para la descarga, procesamiento, segmentación y análisis de los archivos de audio.

\end{document}


